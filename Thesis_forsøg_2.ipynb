{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMaJPvLRZrDOYJOApSAdMw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05d4fd743890424485f42c10161b38a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc58b24f371d4ca68934991dcfa45396",
              "IPY_MODEL_f83c9d8cc37c4c7baa7794c7b49cec80",
              "IPY_MODEL_03c0a277f00b47cf8890b7e2b1dcad34"
            ],
            "layout": "IPY_MODEL_e2cd814e9b94471fa160d4023a2219b0"
          }
        },
        "bc58b24f371d4ca68934991dcfa45396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c51e828d9a6498c8623f094db6012c4",
            "placeholder": "​",
            "style": "IPY_MODEL_3cb657e394c644088def399878192d6e",
            "value": "Batches: 100%"
          }
        },
        "f83c9d8cc37c4c7baa7794c7b49cec80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a61674833b644ad1ae97a060a64088ba",
            "max": 88,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35d89c8ab3524492997de2e8d31ea978",
            "value": 88
          }
        },
        "03c0a277f00b47cf8890b7e2b1dcad34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe92d5f8c9447168f811e0a7dd9ac02",
            "placeholder": "​",
            "style": "IPY_MODEL_96a63bb204754be6b6319d89c0558492",
            "value": " 88/88 [00:08&lt;00:00, 22.98it/s]"
          }
        },
        "e2cd814e9b94471fa160d4023a2219b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c51e828d9a6498c8623f094db6012c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb657e394c644088def399878192d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a61674833b644ad1ae97a060a64088ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d89c8ab3524492997de2e8d31ea978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fe92d5f8c9447168f811e0a7dd9ac02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96a63bb204754be6b6319d89c0558492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaHolmlund/Thesis/blob/main/Thesis_fors%C3%B8g_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📦 **Packages**"
      ],
      "metadata": {
        "id": "6L22_GQE5Ok_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QgTDGkRau9xd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# DataMapPlot\n",
        "!git clone https://github.com/TutteInstitute/datamapplot.git\n",
        "!pip install datamapplot/.\n",
        "\n",
        "# GPU-accelerated HDBSCAN + UMAP\n",
        "!pip install cudf-cu12 dask-cudf-cu12 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cugraph-cu12 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cupy-cuda12x -f https://pip.cupy.dev/aarch64\n",
        "\n",
        "# OpenAI\n",
        "!pip install openai\n",
        "\n",
        "# Topic Modelling\n",
        "!pip install bertopic datasets\n",
        "!pip install sentence-transformers\n",
        "\n",
        "# Progress bar\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📄 **Data**"
      ],
      "metadata": {
        "id": "N-8L1M1s52wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import pandas as pd\n",
        "\n",
        "# Import raw data\n",
        "berlingske = pd.read_csv('raw_article_Berlingske_2024-03-04.csv')\n",
        "jyllands_posten = pd.read_csv('raw_article_Jyllands_Posten_2024-03-04.csv')\n",
        "politiken = pd.read_csv('raw_article_Politiken_2024-03-04.csv')\n",
        "\n",
        "# Merge the datasets\n",
        "dataset = pd.concat([berlingske, jyllands_posten, politiken], ignore_index=True)"
      ],
      "metadata": {
        "id": "_svn7_rV5kOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Light Pre-Processing"
      ],
      "metadata": {
        "id": "-GQALbD5fmTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing rows with NaN values in the Article column\n",
        "dataset = dataset.dropna(subset=['Article'])\n",
        "\n",
        "# Reset the index\n",
        "dataset.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "ECL8YZU0f18f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging 'Brief' and 'Article' into one column 'Content'\n",
        "dataset['Content'] = dataset.apply(lambda row: str(row['Article']) if pd.isna(row['Brief']) else str(row['Brief']) + \" \" + str(row['Article']), axis=1)"
      ],
      "metadata": {
        "id": "JB3WnaEMxbNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "QcBUj-Ggu_gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example view of title and content\n",
        "print(textwrap.fill(dataset['Title'][7050], width=140))\n",
        "print(textwrap.fill(dataset['Content'][7050], width=140))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiNBgJP8_MZf",
        "outputId": "fc1b6c78-ffb8-4851-e792-4467b742124f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dansk intelligent hjertealarm skal redde liv\n",
            "Danske forskere udvikler en alarm, der kan forudsige hjerteanfald hos personer med avancerede pacemakere. Der er ikke oplæsning af denne\n",
            "artikel, så den oplæses derfor med maskinstemme. Kontakt os gerne påautomatiskoplaesning@pol.dk, hvis du hører ord, hvis udtale kan\n",
            "forbedres. Indtil nu har danske hjertelæger selv skullet analysere tusindvis af signaler og sendinger fra pacemakere og andre hjerteenheder\n",
            "landet over, og dermed vurdere om patienten har brug for hjælp. Men en ny intelligent hjertealarm skal i fremtiden give lægerne en hjælpende\n",
            "hånd. Den danskudviklede hjertealarm, der potentielt kan redde menneskeliv, bliver i øjeblikket testet af lægerne på Rigshospitalet. Tariq\n",
            "Andersen, der er adjunkt på Datalogisk Institut på Københavns Universitet, er med til at teste alarmen. » Alarmen består af en algoritme,\n",
            "der kigger på data fra folks hjerteenheder. Den kigger så på det data og laver en forudsigelse af, hvad risikoen er for et hjerteanfald\n",
            "inden for 30 dage, siger Tariq Andersen. »Den hjælper lægerne med at tage en beslutning i forhold til, hvad de skal gøre, når de modtager\n",
            "data fra folks implantérbare hjertestartere (avanceret pacemaker, red.). Den kunstige intelligens trækker på data fra over 12.000\n",
            "hjerteepisoder, som den er trænet til at genkende mønstre i. Typisk tager det en læge omkring 20 minutter at analysere tal fra en\n",
            "hjerteenhed, forklarer Tariq Andersen. Derefter skal lægen tage en beslutning om, hvorvidt man skal kontakte patienten. »Lige nu ser vi, at\n",
            "alarmen sparer dem tid og støtter lægens beslutning, så de er mere sikre. »Lægerne synes, det er rigtig spændende. Når vi sidder og arbejder\n",
            "med den, bliver det nærmest som at se skakspillere spille mod computeren, siger han. Ifølge Hjerteforeningen bliver 4000 danskere årligt\n",
            "ramt af hjertestop uden for et hospital. 12 procent af dem overlever. Hjertealarmen testes ikke fuldt ud på Rigshospitalet endnu. I\n",
            "øjeblikket arbejder Tariq Andersen og lægerne med den ved at se på tidligere hjertetilfælde, og hvordan den i så fald kunne hjælpe. Tariq\n",
            "Andersen vil derfor heller ikke gisne om, hvor værdifuld alarmen kan blive for lægerne. Men den har et stort potentiale, da Danmark er\n",
            "førende på området, forklarer han. »Det er en algoritme, og den kan køre over hele verden. Det er nemt at distribuere. I verden følger 7500\n",
            "hospitaler eller kliniker patienter med hjerteenheder. De vil alle kunne bruge den her alarm, siger han. Alarmen og dens algoritme udvikles\n",
            "i samarbejde mellem mediko-virksomheden Vital Beats, Københavns Universitet og Rigshospitalet. ritzau Som abonnent kan du ubegrænset dele\n",
            "artikler med dine venner og familie. Læs mere om fordelene ved et abonnementher. Der skete enfejl, prøv igen senere eller søg hjælp via\n",
            "voreskundecenter En helt ny podcast med tre aktuelle historier alle hverdage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset['Content'])"
      ],
      "metadata": {
        "id": "oM63XlaSaVUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 💬 **Utilizing OpenAI and Together.ai API**"
      ],
      "metadata": {
        "id": "hXd8iXENBeT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "iS23ugDPgwEe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "S3DwQqYIhoUz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')"
      ],
      "metadata": {
        "id": "Rl4cHjOvhqDu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(base_url=\"https://api.together.xyz/v1\", api_key=TOGETHER_API_KEY)"
      ],
      "metadata": {
        "id": "FcwxROvDhyg4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing that the model is loaded correctly by running a prompt\n",
        "system = \"You are a helpful assistant\"\n",
        "user = \"Explain artificial intelligence as if I am 5?\""
      ],
      "metadata": {
        "id": "xCy4x9IiHkhF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": user}\n",
        "  ],\n",
        "  temperature=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "2CrWVFnxHtCJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(textwrap.fill(completion.choices[0].message.content, width=140))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLMGfz3xHvZ6",
        "outputId": "482ab403-12e7-4eec-99a1-11b932aa21e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, imagine you have a toy robot that can learn and do things on its own. Artificial intelligence is like giving that toy robot the\n",
            "ability to understand and solve problems, just like a real person. It can learn from experiences, recognize things, and even make decisions.\n",
            "So, AI is like making smart robots or machines that can think and work like humans.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prompt Engineering for Translation and Data Cleaning**"
      ],
      "metadata": {
        "id": "2xc8ZpC99uIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize progress bar\n",
        "pbar = tqdm(total=len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMb-F9vTBl7J",
        "outputId": "7d86afab-88dc-45a4-dbe1-39d39054073c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Translating Titles**"
      ],
      "metadata": {
        "id": "92cCJueK11cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translating article titles to English\n",
        "\n",
        "# Iterate over dataset rows\n",
        "for index, row in dataset.iterrows():\n",
        "    # Access title content from the 'Title' column\n",
        "    title_content = row['Title']\n",
        "\n",
        "    # Define the system and user messages\n",
        "    system = \"You are a helpful, respectful and honest assistant specialized in translating text data from Danish to English.\"\n",
        "    user = \"Translate the following text from Danish to English:\\n\\n\" + title_content\n",
        "\n",
        "    # Create completion using Together.ai API and Mistral\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": user}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    # Get cleaned text from completion\n",
        "    translated_title = textwrap.fill(completion.choices[0].message.content, width=100)\n",
        "\n",
        "    # Add cleaned text to new column 'Article_cleaned'\n",
        "    dataset.at[index, 'Title_translated'] = translated_title\n",
        "\n",
        "    # Update progress bar\n",
        "    pbar.update(1)\n",
        "\n",
        "# Close progress bar\n",
        "pbar.close()"
      ],
      "metadata": {
        "id": "TMrNNI9o0RVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[['Title', 'Title_translated']].head(20)"
      ],
      "metadata": {
        "id": "1LuX8qr30wpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Translating and Cleaning Content**"
      ],
      "metadata": {
        "id": "rcSLvHjKQtHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translating the Content column and cleaning the translated content\n",
        "\n",
        "# Iterate over dataset rows\n",
        "for index, row in dataset.iterrows():\n",
        "    # Access content from the 'Content' column\n",
        "    article_content = row['Content']\n",
        "\n",
        "    # Define the system and user messages for translation\n",
        "    translation_system = \"You are a helpful, respectful and honest assistant specialized in translating text data from Danish to English.\"\n",
        "    translation_user = \"Translate the following text from Danish to English:\\n\\n\" + article_content\n",
        "\n",
        "    # Create completion for translation using Together.ai API and Mistral\n",
        "    translation_completion = client.chat.completions.create(\n",
        "        model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": translation_system},\n",
        "            {\"role\": \"user\", \"content\": translation_user}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    # Get translated text\n",
        "    translated_content = translation_completion.choices[0].message.content\n",
        "\n",
        "    # Add translated text to new column 'Content_translated'\n",
        "    dataset.at[index, 'Content_translated'] = translated_content\n",
        "\n",
        "    # Define the system and user messages for cleaning\n",
        "    cleaning_system = \"You are a helpful, respectful and honest assistant specialized in cleaning text data\"\n",
        "    cleaning_user = \"Clean the following text. Keep only the core content and remove irrelevent information:\\n\\n\" + translated_content\n",
        "\n",
        "    # Create completion for cleaning using Together.ai API and Mistral\n",
        "    cleaning_completion = client.chat.completions.create(\n",
        "        model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": cleaning_system},\n",
        "            {\"role\": \"user\", \"content\": cleaning_user}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    # Get cleaned text\n",
        "    cleaned_content = cleaning_completion.choices[0].message.content\n",
        "\n",
        "    # Add cleaned text to new column 'Content_cleaned'\n",
        "    dataset.at[index, 'Content_cleaned'] = cleaned_content\n",
        "\n",
        "    # Update progress bar\n",
        "    pbar.update(1)\n",
        "\n",
        "# Close progress bar\n",
        "pbar.close()"
      ],
      "metadata": {
        "id": "BesM31WzCQEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[['Content', 'Content_translated', 'Content_cleaned']].head()"
      ],
      "metadata": {
        "id": "626r85AuCU9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the cleaned dataset as csv\n",
        "dataset.to_csv('dataset_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "OlCE9YQIFsct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Filtering the Dataset**"
      ],
      "metadata": {
        "id": "g4M1yQt0bISi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter dataset into three distinct time periods\n",
        "time_period ='2014_2016'\n",
        "time_period_viz = '2014-2016'\n",
        "\n",
        "dataset_filtered = dataset[(dataset['Date'] >= '2014-01-01') & (dataset['Date'] <= '2016-12-31')] # Time period 1\n",
        "#dataset_filtered = dataset[(dataset['Date'] >= '2017-01-01') & (dataset['Date'] <= '2019-12-31')] # Time period 2\n",
        "#dataset_filtered = dataset[dataset['Date'] >= '2020-01-01'] # Time period 3"
      ],
      "metadata": {
        "id": "_VSoWTTRaoWg"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_filtered['Content_cleaned'])"
      ],
      "metadata": {
        "id": "8EnmerzTdYHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Create a dictionary instead of a pandas dataframe\n",
        "data_dict = {\n",
        "    \"Content_cleaned\": dataset_filtered[\"Content_cleaned\"].tolist(),\n",
        "    \"Title_translated\": dataset_filtered[\"Title_translated\"].tolist()\n",
        "}\n",
        "\n",
        "# Create a dataset object\n",
        "dataset_dict = Dataset.from_dict(data_dict)\n",
        "\n",
        "# Extract cleaned content to train on and corresponding titles\n",
        "content = dataset_dict[\"Content_cleaned\"]\n",
        "titles = dataset_dict[\"Title_translated\"]"
      ],
      "metadata": {
        "id": "65cUnIyz7JY3"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Promt Engineering for Topic Labelling**"
      ],
      "metadata": {
        "id": "S4-XweFM8G_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prompt Template**\n",
        "\n"
      ],
      "metadata": {
        "id": "vn3hhEhOnbTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# System prompt describes information given to all conversations\n",
        "system_prompt = \"\"\"\n",
        "You are a helpful, respectful and honest assistant specialized in labeling topics of news articles.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PePA6zjii98x"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompt demonstrating the output we are looking for\n",
        "example_prompt = \"\"\"\n",
        "I have a topic that contains the following documents:\n",
        "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
        "- Meat, but especially beef, is the word food in terms of emissions.\n",
        "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
        "\n",
        "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
        "\n",
        "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
        "\"\"\"\n",
        "\n",
        "example_output = \"\"\"Environmental impacts of eating meat\"\"\""
      ],
      "metadata": {
        "id": "m9BEXaGz3RgF"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags\n",
        "main_prompt = \"\"\"\n",
        "I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "\n",
        "The topic is described by the following keywords: '[KEYWORDS]'.\n",
        "\n",
        "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ad-WMWTM3V1D"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = system_prompt + example_prompt + example_output + main_prompt"
      ],
      "metadata": {
        "id": "zX6DVDQg3Xj0"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOirMpgN3Y7_",
        "outputId": "06afc8a8-3a9e-4400-9c0f-4036c8f411fb"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a helpful, respectful and honest assistant specialized in labeling topics of news articles.\n",
            "\n",
            "I have a topic that contains the following documents:\n",
            "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
            "- Meat, but especially beef, is the word food in terms of emissions.\n",
            "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
            "\n",
            "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
            "\n",
            "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
            "Environmental impacts of eating meat\n",
            "I have a topic that contains the following documents:\n",
            "[DOCUMENTS]\n",
            "\n",
            "The topic is described by the following keywords: '[KEYWORDS]'.\n",
            "\n",
            "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🗨️  **BERTopic**"
      ],
      "metadata": {
        "id": "wwsPhdNx3ePg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparing Embeddings**"
      ],
      "metadata": {
        "id": "BYkXwty_3hiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Pre-calculate embeddings\n",
        "embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
        "embeddings = embedding_model.encode(content, show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "05d4fd743890424485f42c10161b38a4",
            "bc58b24f371d4ca68934991dcfa45396",
            "f83c9d8cc37c4c7baa7794c7b49cec80",
            "03c0a277f00b47cf8890b7e2b1dcad34",
            "e2cd814e9b94471fa160d4023a2219b0",
            "9c51e828d9a6498c8623f094db6012c4",
            "3cb657e394c644088def399878192d6e",
            "a61674833b644ad1ae97a060a64088ba",
            "35d89c8ab3524492997de2e8d31ea978",
            "0fe92d5f8c9447168f811e0a7dd9ac02",
            "96a63bb204754be6b6319d89c0558492"
          ]
        },
        "id": "aSBOgaH43e-z",
        "outputId": "8679e10c-975e-439a-9661-fe686e4f98cb"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/88 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05d4fd743890424485f42c10161b38a4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sub-models**"
      ],
      "metadata": {
        "id": "JiETb0t5BJnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cuml.manifold import UMAP\n",
        "from cuml.cluster import HDBSCAN\n",
        "\n",
        "# UMAP parameters\n",
        "umap_model = UMAP(n_components=2, min_dist=0.0, metric='cosine', random_state=42)\n",
        "\n",
        "# HDBSCAN parameters\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n"
      ],
      "metadata": {
        "id": "wlISsD9p3kIt"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-reduce embeddings for visualization purposes\n",
        "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine', random_state=42).fit_transform(embeddings)"
      ],
      "metadata": {
        "id": "Jc2OdFR4BM6k"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Representation Models**"
      ],
      "metadata": {
        "id": "dTPT9dDg_ZAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "I have a topic that is described by the following keywords: [KEYWORDS]\n",
        "In this topic, the following documents are a small but representative subset of all documents in the topic:\n",
        "[DOCUMENTS]\n",
        "\n",
        "Based on the information above, please give a topic label of maximum 4 words:\n",
        "topic: <label>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jzjBOOyj_TvB"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic.representation import OpenAI\n",
        "\n",
        "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance\n",
        "\n",
        "# KeyBERT\n",
        "keybert = KeyBERTInspired()\n",
        "\n",
        "# MMR\n",
        "mmr = MaximalMarginalRelevance(diversity=0.3)\n",
        "\n",
        "openai_rep = OpenAI(client, model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "                    chat=True,\n",
        "                    prompt=prompt,\n",
        "                    nr_docs=5,\n",
        "                    delay_in_seconds=3)\n",
        "\n",
        "\n",
        "# All representation models\n",
        "representation_model = {\n",
        "    \"KeyBERT\": keybert,\n",
        "    \"Mixtral\": openai_rep,\n",
        "    \"MMR\": mmr,\n",
        "}"
      ],
      "metadata": {
        "id": "zyuAsxe__a2r"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔥 **Training**"
      ],
      "metadata": {
        "id": "va8Sm5wm_foM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "topic_model = BERTopic(\n",
        "\n",
        "  # Sub-models\n",
        "  embedding_model=embedding_model,\n",
        "  umap_model=umap_model,\n",
        "  hdbscan_model=hdbscan_model,\n",
        "  representation_model=representation_model,\n",
        "\n",
        "  # Hyperparameters\n",
        "  top_n_words=15,\n",
        "  verbose=True\n",
        ")\n",
        "\n",
        "# Train model\n",
        "topics, probs = topic_model.fit_transform(content, embeddings)"
      ],
      "metadata": {
        "id": "4UTATBjN_cfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get topic info\n",
        "topic_info = topic_model.get_topic_info()\n",
        "\n",
        "# Save topic info as CSV for future reference\n",
        "topic_info.to_csv(f'topic_info_' + time_period + '.csv', index=False)\n",
        "\n",
        "# Show topics\n",
        "topic_info"
      ],
      "metadata": {
        "id": "-ruy0dWU_ipy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic(1, full=True)[\"KeyBERT\"]"
      ],
      "metadata": {
        "id": "NZHitbqr_tgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and add topic labels to the overall dataframe for future reference\n",
        "dataset_filtered['Topic'] = topics\n",
        "\n",
        "# Merge with KeyBERT and Mixtral labels\n",
        "topic_info_subset = topic_info[['Topic', 'KeyBERT', 'Mixtral']]\n",
        "dataset_cleaned_with_labels = pd.merge(dataset_filtered, topic_info_subset, on='Topic', how='left')\n",
        "\n",
        "# Save the dataset as csv\n",
        "dataset_cleaned_with_labels.to_csv(f'dataset_cleaned_with_labels_' + time_period + '.csv', index=False)"
      ],
      "metadata": {
        "id": "A_GAJ0gW4-dF"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cleaned_with_labels"
      ],
      "metadata": {
        "id": "DXlhjQz_-LdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixtral_labels = [label[0][0].split(\"\\n\")[0] for label in topic_model.get_topics(full=True)[\"Mixtral\"].values()]\n",
        "topic_model.set_topic_labels(mixtral_labels)"
      ],
      "metadata": {
        "id": "KiWldE1W_yEM"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📊 **Visualize**"
      ],
      "metadata": {
        "id": "p7IrgDto_9tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_documents(titles, reduced_embeddings=reduced_embeddings, hide_annotations=True, hide_document_hover=False, custom_labels=True, title=f\"News Articles on Artificial Intelligence - Topics from \" + time_period_viz)"
      ],
      "metadata": {
        "id": "O3lvX0j9_0pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "# Prepare logo\n",
        "bertopic_logo_response = requests.get(\n",
        "    \"https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/logo.png\",\n",
        "    stream=True,\n",
        "    headers={'User-Agent': 'My User Agent 1.0'}\n",
        ")\n",
        "bertopic_logo = np.asarray(PIL.Image.open(bertopic_logo_response.raw))"
      ],
      "metadata": {
        "id": "Vp2FdkTr__jy"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datamapplot\n",
        "import re\n",
        "\n",
        "# Create a label for each document\n",
        "llm_labels = [re.sub(r'\\W+', ' ', label[0][0].split(\"\\n\")[0].replace('\"', '')) for label in topic_model.get_topics(full=True)[\"Mixtral\"].values()]\n",
        "llm_labels = [label if label else \"Unlabelled\" for label in llm_labels]\n",
        "all_labels = [llm_labels[topic+topic_model._outliers] if topic != -1 else \"Unlabelled\" for topic in topics]\n",
        "\n",
        "# Run the visualization\n",
        "datamapplot.create_plot(\n",
        "    reduced_embeddings,\n",
        "    all_labels,\n",
        "    label_font_size=10,\n",
        "    title=f\"News Articles on Artificial Intelligence - Topics from \" + time_period_viz,\n",
        "    sub_title=\"Topics labeled with `Nous-Hermes-2-Mistral-7B-DPO`\",\n",
        "    label_wrap_width=20,\n",
        "    use_medoids=True,\n",
        "    #logo=bertopic_logo,\n",
        "    #logo_width=0.16\n",
        ")"
      ],
      "metadata": {
        "id": "7H5LcBMJAD3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xHpFw78QlSup"
      },
      "execution_count": 161,
      "outputs": []
    }
  ]
}