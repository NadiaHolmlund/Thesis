{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMaJPvLRZrDOYJOApSAdMw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05d4fd743890424485f42c10161b38a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc58b24f371d4ca68934991dcfa45396",
              "IPY_MODEL_f83c9d8cc37c4c7baa7794c7b49cec80",
              "IPY_MODEL_03c0a277f00b47cf8890b7e2b1dcad34"
            ],
            "layout": "IPY_MODEL_e2cd814e9b94471fa160d4023a2219b0"
          }
        },
        "bc58b24f371d4ca68934991dcfa45396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c51e828d9a6498c8623f094db6012c4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3cb657e394c644088def399878192d6e",
            "value": "Batches:‚Äá100%"
          }
        },
        "f83c9d8cc37c4c7baa7794c7b49cec80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a61674833b644ad1ae97a060a64088ba",
            "max": 88,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35d89c8ab3524492997de2e8d31ea978",
            "value": 88
          }
        },
        "03c0a277f00b47cf8890b7e2b1dcad34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe92d5f8c9447168f811e0a7dd9ac02",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_96a63bb204754be6b6319d89c0558492",
            "value": "‚Äá88/88‚Äá[00:08&lt;00:00,‚Äá22.98it/s]"
          }
        },
        "e2cd814e9b94471fa160d4023a2219b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c51e828d9a6498c8623f094db6012c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb657e394c644088def399878192d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a61674833b644ad1ae97a060a64088ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d89c8ab3524492997de2e8d31ea978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fe92d5f8c9447168f811e0a7dd9ac02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96a63bb204754be6b6319d89c0558492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadiaHolmlund/Thesis/blob/main/Thesis_fors%C3%B8g_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ **Packages**"
      ],
      "metadata": {
        "id": "6L22_GQE5Ok_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QgTDGkRau9xd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# DataMapPlot\n",
        "!git clone https://github.com/TutteInstitute/datamapplot.git\n",
        "!pip install datamapplot/.\n",
        "\n",
        "# GPU-accelerated HDBSCAN + UMAP\n",
        "!pip install cudf-cu12 dask-cudf-cu12 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cugraph-cu12 --extra-index-url=https://pypi.nvidia.com\n",
        "!pip install cupy-cuda12x -f https://pip.cupy.dev/aarch64\n",
        "\n",
        "# OpenAI\n",
        "!pip install openai\n",
        "\n",
        "# Topic Modelling\n",
        "!pip install bertopic datasets\n",
        "!pip install sentence-transformers\n",
        "\n",
        "# Progress bar\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìÑ **Data**"
      ],
      "metadata": {
        "id": "N-8L1M1s52wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import pandas as pd\n",
        "\n",
        "# Import raw data\n",
        "berlingske = pd.read_csv('raw_article_Berlingske_2024-03-04.csv')\n",
        "jyllands_posten = pd.read_csv('raw_article_Jyllands_Posten_2024-03-04.csv')\n",
        "politiken = pd.read_csv('raw_article_Politiken_2024-03-04.csv')\n",
        "\n",
        "# Merge the datasets\n",
        "dataset = pd.concat([berlingske, jyllands_posten, politiken], ignore_index=True)"
      ],
      "metadata": {
        "id": "_svn7_rV5kOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Light Pre-Processing"
      ],
      "metadata": {
        "id": "-GQALbD5fmTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing rows with NaN values in the Article column\n",
        "dataset = dataset.dropna(subset=['Article'])\n",
        "\n",
        "# Reset the index\n",
        "dataset.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "ECL8YZU0f18f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging 'Brief' and 'Article' into one column 'Content'\n",
        "dataset['Content'] = dataset.apply(lambda row: str(row['Article']) if pd.isna(row['Brief']) else str(row['Brief']) + \" \" + str(row['Article']), axis=1)"
      ],
      "metadata": {
        "id": "JB3WnaEMxbNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "QcBUj-Ggu_gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example view of title and content\n",
        "print(textwrap.fill(dataset['Title'][7050], width=140))\n",
        "print(textwrap.fill(dataset['Content'][7050], width=140))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiNBgJP8_MZf",
        "outputId": "fc1b6c78-ffb8-4851-e792-4467b742124f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dansk intelligent hjertealarm skal redde liv\n",
            "Danske forskere udvikler en alarm, der kan forudsige hjerteanfald hos personer med avancerede pacemakere. Der er ikke opl√¶sning af denne\n",
            "artikel, s√• den opl√¶ses derfor med maskinstemme. Kontakt os gerne p√•automatiskoplaesning@pol.dk, hvis du h√∏rer ord, hvis udtale kan\n",
            "forbedres. Indtil nu har danske hjertel√¶ger selv skullet analysere tusindvis af signaler og sendinger fra pacemakere og andre hjerteenheder\n",
            "landet over, og dermed vurdere om patienten har brug for hj√¶lp. Men en ny intelligent hjertealarm skal i fremtiden give l√¶gerne en hj√¶lpende\n",
            "h√•nd. Den danskudviklede hjertealarm, der potentielt kan redde menneskeliv, bliver i √∏jeblikket testet af l√¶gerne p√• Rigshospitalet. Tariq\n",
            "Andersen, der er adjunkt p√• Datalogisk Institut p√• K√∏benhavns Universitet, er med til at teste alarmen. ¬ª Alarmen best√•r af en algoritme,\n",
            "der kigger p√• data fra folks hjerteenheder. Den kigger s√• p√• det data og laver en forudsigelse af, hvad risikoen er for et hjerteanfald\n",
            "inden for 30 dage, siger Tariq Andersen. ¬ªDen hj√¶lper l√¶gerne med at tage en beslutning i forhold til, hvad de skal g√∏re, n√•r de modtager\n",
            "data fra folks implant√©rbare hjertestartere (avanceret pacemaker, red.). Den kunstige intelligens tr√¶kker p√• data fra over 12.000\n",
            "hjerteepisoder, som den er tr√¶net til at genkende m√∏nstre i. Typisk tager det en l√¶ge omkring 20 minutter at analysere tal fra en\n",
            "hjerteenhed, forklarer Tariq Andersen. Derefter skal l√¶gen tage en beslutning om, hvorvidt man skal kontakte patienten. ¬ªLige nu ser vi, at\n",
            "alarmen sparer dem tid og st√∏tter l√¶gens beslutning, s√• de er mere sikre. ¬ªL√¶gerne synes, det er rigtig sp√¶ndende. N√•r vi sidder og arbejder\n",
            "med den, bliver det n√¶rmest som at se skakspillere spille mod computeren, siger han. If√∏lge Hjerteforeningen bliver 4000 danskere √•rligt\n",
            "ramt af hjertestop uden for et hospital. 12 procent af dem overlever. Hjertealarmen testes ikke fuldt ud p√• Rigshospitalet endnu. I\n",
            "√∏jeblikket arbejder Tariq Andersen og l√¶gerne med den ved at se p√• tidligere hjertetilf√¶lde, og hvordan den i s√• fald kunne hj√¶lpe. Tariq\n",
            "Andersen vil derfor heller ikke gisne om, hvor v√¶rdifuld alarmen kan blive for l√¶gerne. Men den har et stort potentiale, da Danmark er\n",
            "f√∏rende p√• omr√•det, forklarer han. ¬ªDet er en algoritme, og den kan k√∏re over hele verden. Det er nemt at distribuere. I verden f√∏lger 7500\n",
            "hospitaler eller kliniker patienter med hjerteenheder. De vil alle kunne bruge den her alarm, siger han. Alarmen og dens algoritme udvikles\n",
            "i samarbejde mellem mediko-virksomheden Vital Beats, K√∏benhavns Universitet og Rigshospitalet. ritzau Som abonnent kan du ubegr√¶nset dele\n",
            "artikler med dine venner og familie. L√¶s mere om fordelene ved et abonnementher. Der skete enfejl, pr√∏v igen senere eller s√∏g hj√¶lp via\n",
            "voreskundecenter En helt ny podcast med tre aktuelle historier alle hverdage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset['Content'])"
      ],
      "metadata": {
        "id": "oM63XlaSaVUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí¨ **Utilizing OpenAI and Together.ai API**"
      ],
      "metadata": {
        "id": "hXd8iXENBeT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "iS23ugDPgwEe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "S3DwQqYIhoUz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOGETHER_API_KEY = userdata.get('TOGETHER_API_KEY')"
      ],
      "metadata": {
        "id": "Rl4cHjOvhqDu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(base_url=\"https://api.together.xyz/v1\", api_key=TOGETHER_API_KEY)"
      ],
      "metadata": {
        "id": "FcwxROvDhyg4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing that the model is loaded correctly by running a prompt\n",
        "system = \"You are a helpful assistant\"\n",
        "user = \"Explain artificial intelligence as if I am 5?\""
      ],
      "metadata": {
        "id": "xCy4x9IiHkhF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system},\n",
        "    {\"role\": \"user\", \"content\": user}\n",
        "  ],\n",
        "  temperature=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "2CrWVFnxHtCJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(textwrap.fill(completion.choices[0].message.content, width=140))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLMGfz3xHvZ6",
        "outputId": "482ab403-12e7-4eec-99a1-11b932aa21e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, imagine you have a toy robot that can learn and do things on its own. Artificial intelligence is like giving that toy robot the\n",
            "ability to understand and solve problems, just like a real person. It can learn from experiences, recognize things, and even make decisions.\n",
            "So, AI is like making smart robots or machines that can think and work like humans.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prompt Engineering for Translation and Data Cleaning**"
      ],
      "metadata": {
        "id": "2xc8ZpC99uIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Initialize progress bar\n",
        "pbar = tqdm(total=len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMb-F9vTBl7J",
        "outputId": "7d86afab-88dc-45a4-dbe1-39d39054073c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Translating Titles**"
      ],
      "metadata": {
        "id": "92cCJueK11cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translating article titles to English\n",
        "\n",
        "# Iterate over dataset rows\n",
        "for index, row in dataset.iterrows():\n",
        "    # Access title content from the 'Title' column\n",
        "    title_content = row['Title']\n",
        "\n",
        "    # Define the system and user messages\n",
        "    system = \"You are a helpful, respectful and honest assistant specialized in translating text data from Danish to English.\"\n",
        "    user = \"Translate the following text from Danish to English:\\n\\n\" + title_content\n",
        "\n",
        "    # Create completion using Together.ai API and Mistral\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": user}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    # Get cleaned text from completion\n",
        "    translated_title = textwrap.fill(completion.choices[0].message.content, width=100)\n",
        "\n",
        "    # Add cleaned text to new column 'Article_cleaned'\n",
        "    dataset.at[index, 'Title_translated'] = translated_title\n",
        "\n",
        "    # Update progress bar\n",
        "    pbar.update(1)\n",
        "\n",
        "# Close progress bar\n",
        "pbar.close()"
      ],
      "metadata": {
        "id": "TMrNNI9o0RVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[['Title', 'Title_translated']].head(20)"
      ],
      "metadata": {
        "id": "1LuX8qr30wpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Translating and Cleaning Content**"
      ],
      "metadata": {
        "id": "rcSLvHjKQtHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translating the Content column and cleaning the translated content\n",
        "\n",
        "# Iterate over dataset rows\n",
        "for index, row in dataset.iterrows():\n",
        "    # Access content from the 'Content' column\n",
        "    article_content = row['Content']\n",
        "\n",
        "    # Define the system and user messages for translation\n",
        "    translation_system = \"You are a helpful, respectful and honest assistant specialized in translating text data from Danish to English.\"\n",
        "    translation_user = \"Translate the following text from Danish to English:\\n\\n\" + article_content\n",
        "\n",
        "    # Create completion for translation using Together.ai API and Mistral\n",
        "    translation_completion = client.chat.completions.create(\n",
        "        model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": translation_system},\n",
        "            {\"role\": \"user\", \"content\": translation_user}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    # Get translated text\n",
        "    translated_content = translation_completion.choices[0].message.content\n",
        "\n",
        "    # Add translated text to new column 'Content_translated'\n",
        "    dataset.at[index, 'Content_translated'] = translated_content\n",
        "\n",
        "    # Define the system and user messages for cleaning\n",
        "    cleaning_system = \"You are a helpful, respectful and honest assistant specialized in cleaning text data\"\n",
        "    cleaning_user = \"Clean the following text. Keep only the core content and remove irrelevent information:\\n\\n\" + translated_content\n",
        "\n",
        "    # Create completion for cleaning using Together.ai API and Mistral\n",
        "    cleaning_completion = client.chat.completions.create(\n",
        "        model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": cleaning_system},\n",
        "            {\"role\": \"user\", \"content\": cleaning_user}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    # Get cleaned text\n",
        "    cleaned_content = cleaning_completion.choices[0].message.content\n",
        "\n",
        "    # Add cleaned text to new column 'Content_cleaned'\n",
        "    dataset.at[index, 'Content_cleaned'] = cleaned_content\n",
        "\n",
        "    # Update progress bar\n",
        "    pbar.update(1)\n",
        "\n",
        "# Close progress bar\n",
        "pbar.close()"
      ],
      "metadata": {
        "id": "BesM31WzCQEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[['Content', 'Content_translated', 'Content_cleaned']].head()"
      ],
      "metadata": {
        "id": "626r85AuCU9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the cleaned dataset as csv\n",
        "dataset.to_csv('dataset_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "OlCE9YQIFsct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Filtering the Dataset**"
      ],
      "metadata": {
        "id": "g4M1yQt0bISi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter dataset into three distinct time periods\n",
        "time_period ='2014_2016'\n",
        "time_period_viz = '2014-2016'\n",
        "\n",
        "dataset_filtered = dataset[(dataset['Date'] >= '2014-01-01') & (dataset['Date'] <= '2016-12-31')] # Time period 1\n",
        "#dataset_filtered = dataset[(dataset['Date'] >= '2017-01-01') & (dataset['Date'] <= '2019-12-31')] # Time period 2\n",
        "#dataset_filtered = dataset[dataset['Date'] >= '2020-01-01'] # Time period 3"
      ],
      "metadata": {
        "id": "_VSoWTTRaoWg"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_filtered['Content_cleaned'])"
      ],
      "metadata": {
        "id": "8EnmerzTdYHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Create a dictionary instead of a pandas dataframe\n",
        "data_dict = {\n",
        "    \"Content_cleaned\": dataset_filtered[\"Content_cleaned\"].tolist(),\n",
        "    \"Title_translated\": dataset_filtered[\"Title_translated\"].tolist()\n",
        "}\n",
        "\n",
        "# Create a dataset object\n",
        "dataset_dict = Dataset.from_dict(data_dict)\n",
        "\n",
        "# Extract cleaned content to train on and corresponding titles\n",
        "content = dataset_dict[\"Content_cleaned\"]\n",
        "titles = dataset_dict[\"Title_translated\"]"
      ],
      "metadata": {
        "id": "65cUnIyz7JY3"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Promt Engineering for Topic Labelling**"
      ],
      "metadata": {
        "id": "S4-XweFM8G_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prompt Template**\n",
        "\n"
      ],
      "metadata": {
        "id": "vn3hhEhOnbTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# System prompt describes information given to all conversations\n",
        "system_prompt = \"\"\"\n",
        "You are a helpful, respectful and honest assistant specialized in labeling topics of news articles.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PePA6zjii98x"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompt demonstrating the output we are looking for\n",
        "example_prompt = \"\"\"\n",
        "I have a topic that contains the following documents:\n",
        "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
        "- Meat, but especially beef, is the word food in terms of emissions.\n",
        "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
        "\n",
        "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
        "\n",
        "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
        "\"\"\"\n",
        "\n",
        "example_output = \"\"\"Environmental impacts of eating meat\"\"\""
      ],
      "metadata": {
        "id": "m9BEXaGz3RgF"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our main prompt with documents ([DOCUMENTS]) and keywords ([KEYWORDS]) tags\n",
        "main_prompt = \"\"\"\n",
        "I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "\n",
        "The topic is described by the following keywords: '[KEYWORDS]'.\n",
        "\n",
        "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ad-WMWTM3V1D"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = system_prompt + example_prompt + example_output + main_prompt"
      ],
      "metadata": {
        "id": "zX6DVDQg3Xj0"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOirMpgN3Y7_",
        "outputId": "06afc8a8-3a9e-4400-9c0f-4036c8f411fb"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a helpful, respectful and honest assistant specialized in labeling topics of news articles.\n",
            "\n",
            "I have a topic that contains the following documents:\n",
            "- Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
            "- Meat, but especially beef, is the word food in terms of emissions.\n",
            "- Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
            "\n",
            "The topic is described by the following keywords: 'meat, beef, eat, eating, emissions, steak, food, health, processed, chicken'.\n",
            "\n",
            "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
            "Environmental impacts of eating meat\n",
            "I have a topic that contains the following documents:\n",
            "[DOCUMENTS]\n",
            "\n",
            "The topic is described by the following keywords: '[KEYWORDS]'.\n",
            "\n",
            "Based on the information about the topic above, please create a short label of this topic. Make sure you to only return the label and nothing more.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üó®Ô∏è  **BERTopic**"
      ],
      "metadata": {
        "id": "wwsPhdNx3ePg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preparing Embeddings**"
      ],
      "metadata": {
        "id": "BYkXwty_3hiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Pre-calculate embeddings\n",
        "embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
        "embeddings = embedding_model.encode(content, show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "05d4fd743890424485f42c10161b38a4",
            "bc58b24f371d4ca68934991dcfa45396",
            "f83c9d8cc37c4c7baa7794c7b49cec80",
            "03c0a277f00b47cf8890b7e2b1dcad34",
            "e2cd814e9b94471fa160d4023a2219b0",
            "9c51e828d9a6498c8623f094db6012c4",
            "3cb657e394c644088def399878192d6e",
            "a61674833b644ad1ae97a060a64088ba",
            "35d89c8ab3524492997de2e8d31ea978",
            "0fe92d5f8c9447168f811e0a7dd9ac02",
            "96a63bb204754be6b6319d89c0558492"
          ]
        },
        "id": "aSBOgaH43e-z",
        "outputId": "8679e10c-975e-439a-9661-fe686e4f98cb"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/88 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05d4fd743890424485f42c10161b38a4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sub-models**"
      ],
      "metadata": {
        "id": "JiETb0t5BJnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cuml.manifold import UMAP\n",
        "from cuml.cluster import HDBSCAN\n",
        "\n",
        "# UMAP parameters\n",
        "umap_model = UMAP(n_components=2, min_dist=0.0, metric='cosine', random_state=42)\n",
        "\n",
        "# HDBSCAN parameters\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n"
      ],
      "metadata": {
        "id": "wlISsD9p3kIt"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-reduce embeddings for visualization purposes\n",
        "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine', random_state=42).fit_transform(embeddings)"
      ],
      "metadata": {
        "id": "Jc2OdFR4BM6k"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Representation Models**"
      ],
      "metadata": {
        "id": "dTPT9dDg_ZAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "I have a topic that is described by the following keywords: [KEYWORDS]\n",
        "In this topic, the following documents are a small but representative subset of all documents in the topic:\n",
        "[DOCUMENTS]\n",
        "\n",
        "Based on the information above, please give a topic label of maximum 4 words:\n",
        "topic: <label>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jzjBOOyj_TvB"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic.representation import OpenAI\n",
        "\n",
        "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance\n",
        "\n",
        "# KeyBERT\n",
        "keybert = KeyBERTInspired()\n",
        "\n",
        "# MMR\n",
        "mmr = MaximalMarginalRelevance(diversity=0.3)\n",
        "\n",
        "openai_rep = OpenAI(client, model=\"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\",\n",
        "                    chat=True,\n",
        "                    prompt=prompt,\n",
        "                    nr_docs=5,\n",
        "                    delay_in_seconds=3)\n",
        "\n",
        "\n",
        "# All representation models\n",
        "representation_model = {\n",
        "    \"KeyBERT\": keybert,\n",
        "    \"Mixtral\": openai_rep,\n",
        "    \"MMR\": mmr,\n",
        "}"
      ],
      "metadata": {
        "id": "zyuAsxe__a2r"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî• **Training**"
      ],
      "metadata": {
        "id": "va8Sm5wm_foM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "topic_model = BERTopic(\n",
        "\n",
        "  # Sub-models\n",
        "  embedding_model=embedding_model,\n",
        "  umap_model=umap_model,\n",
        "  hdbscan_model=hdbscan_model,\n",
        "  representation_model=representation_model,\n",
        "\n",
        "  # Hyperparameters\n",
        "  top_n_words=15,\n",
        "  verbose=True\n",
        ")\n",
        "\n",
        "# Train model\n",
        "topics, probs = topic_model.fit_transform(content, embeddings)"
      ],
      "metadata": {
        "id": "4UTATBjN_cfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get topic info\n",
        "topic_info = topic_model.get_topic_info()\n",
        "\n",
        "# Save topic info as CSV for future reference\n",
        "topic_info.to_csv(f'topic_info_' + time_period + '.csv', index=False)\n",
        "\n",
        "# Show topics\n",
        "topic_info"
      ],
      "metadata": {
        "id": "-ruy0dWU_ipy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic(1, full=True)[\"KeyBERT\"]"
      ],
      "metadata": {
        "id": "NZHitbqr_tgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and add topic labels to the overall dataframe for future reference\n",
        "dataset_filtered['Topic'] = topics\n",
        "\n",
        "# Merge with KeyBERT and Mixtral labels\n",
        "topic_info_subset = topic_info[['Topic', 'KeyBERT', 'Mixtral']]\n",
        "dataset_cleaned_with_labels = pd.merge(dataset_filtered, topic_info_subset, on='Topic', how='left')\n",
        "\n",
        "# Save the dataset as csv\n",
        "dataset_cleaned_with_labels.to_csv(f'dataset_cleaned_with_labels_' + time_period + '.csv', index=False)"
      ],
      "metadata": {
        "id": "A_GAJ0gW4-dF"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cleaned_with_labels"
      ],
      "metadata": {
        "id": "DXlhjQz_-LdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixtral_labels = [label[0][0].split(\"\\n\")[0] for label in topic_model.get_topics(full=True)[\"Mixtral\"].values()]\n",
        "topic_model.set_topic_labels(mixtral_labels)"
      ],
      "metadata": {
        "id": "KiWldE1W_yEM"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä **Visualize**"
      ],
      "metadata": {
        "id": "p7IrgDto_9tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_documents(titles, reduced_embeddings=reduced_embeddings, hide_annotations=True, hide_document_hover=False, custom_labels=True, title=f\"News Articles on Artificial Intelligence - Topics from \" + time_period_viz)"
      ],
      "metadata": {
        "id": "O3lvX0j9_0pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "# Prepare logo\n",
        "bertopic_logo_response = requests.get(\n",
        "    \"https://raw.githubusercontent.com/MaartenGr/BERTopic/master/images/logo.png\",\n",
        "    stream=True,\n",
        "    headers={'User-Agent': 'My User Agent 1.0'}\n",
        ")\n",
        "bertopic_logo = np.asarray(PIL.Image.open(bertopic_logo_response.raw))"
      ],
      "metadata": {
        "id": "Vp2FdkTr__jy"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datamapplot\n",
        "import re\n",
        "\n",
        "# Create a label for each document\n",
        "llm_labels = [re.sub(r'\\W+', ' ', label[0][0].split(\"\\n\")[0].replace('\"', '')) for label in topic_model.get_topics(full=True)[\"Mixtral\"].values()]\n",
        "llm_labels = [label if label else \"Unlabelled\" for label in llm_labels]\n",
        "all_labels = [llm_labels[topic+topic_model._outliers] if topic != -1 else \"Unlabelled\" for topic in topics]\n",
        "\n",
        "# Run the visualization\n",
        "datamapplot.create_plot(\n",
        "    reduced_embeddings,\n",
        "    all_labels,\n",
        "    label_font_size=10,\n",
        "    title=f\"News Articles on Artificial Intelligence - Topics from \" + time_period_viz,\n",
        "    sub_title=\"Topics labeled with `Nous-Hermes-2-Mistral-7B-DPO`\",\n",
        "    label_wrap_width=20,\n",
        "    use_medoids=True,\n",
        "    #logo=bertopic_logo,\n",
        "    #logo_width=0.16\n",
        ")"
      ],
      "metadata": {
        "id": "7H5LcBMJAD3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xHpFw78QlSup"
      },
      "execution_count": 161,
      "outputs": []
    }
  ]
}